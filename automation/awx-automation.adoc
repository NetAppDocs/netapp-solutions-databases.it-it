---
sidebar: sidebar 
permalink: automation/awx-automation.html 
keywords: Linux, RHEL Oracle19c, NFS, ONTAP 
summary: Questa pagina descrive il metodo automatizzato per distribuire Oracle19c sullo storage NetApp ONTAP . 
---
= Procedura di distribuzione passo dopo passo
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Questa pagina descrive il metodo automatizzato per distribuire Oracle19c sullo storage NetApp ONTAP .



== Distribuzione AWX/Tower del database Oracle 19c



=== 1. Crea l'inventario, il gruppo, gli host e le credenziali per il tuo ambiente

Questa sezione descrive la configurazione di inventario, gruppi, host e credenziali di accesso in AWX/Ansible Tower che preparano l'ambiente per l'utilizzo delle soluzioni automatizzate NetApp .

. Configurare l'inventario.
+
.. Vai su Risorse → Inventari → Aggiungi e fai clic su Aggiungi inventario.
.. Inserisci il nome e i dettagli dell'organizzazione, quindi fai clic su Salva.
.. Nella pagina Inventari, fare clic sull'inventario creato.
.. Se sono presenti variabili di inventario, incollarle nel campo delle variabili.
.. Vai al sottomenu Gruppi e fai clic su Aggiungi.
.. Fornire il nome del gruppo per ONTAP, incollare le variabili del gruppo (se presenti) e fare clic su Salva.
.. Ripetere la procedura per un altro gruppo per Oracle.
.. Selezionare il gruppo ONTAP creato, andare al sottomenu Host e fare clic su Aggiungi nuovo host.
.. Fornire l'indirizzo IP dell'IP di gestione del cluster ONTAP , incollare le variabili host (se presenti) e fare clic su Salva.
.. Questo processo deve essere ripetuto per il gruppo Oracle e per l'IP/nome host di gestione dell'host Oracle.


. Creare tipi di credenziali. Per le soluzioni che coinvolgono ONTAP, è necessario configurare il tipo di credenziale in modo che corrisponda alle voci di nome utente e password.
+
.. Vai su Amministrazione → Tipi di credenziali e fai clic su Aggiungi.
.. Fornire il nome e la descrizione.
.. Incolla il seguente contenuto nella Configurazione di input:




[source, cli]
----
fields:
  - id: username
    type: string
    label: Username
  - id: password
    type: string
    label: Password
    secret: true
  - id: vsadmin_password
    type: string
    label: vsadmin_password
    secret: true
----
. Incolla il seguente contenuto nella configurazione dell'iniettore:


[source, cli]
----
extra_vars:
  password: '{{ password }}'
  username: '{{ username }}'
  vsadmin_password: '{{ vsadmin_password }}'
----
. Configurare le credenziali.
+
.. Vai su Risorse → Credenziali e fai clic su Aggiungi.
.. Inserisci il nome e i dettagli dell'organizzazione per ONTAP.
.. Seleziona il tipo di credenziale personalizzato che hai creato per ONTAP.
.. In Dettagli tipo, immettere nome utente, password e vsadmin_password.
.. Fare clic su Torna alle credenziali e quindi su Aggiungi.
.. Inserisci il nome e i dettagli dell'organizzazione per Oracle.
.. Selezionare il tipo di credenziale Macchina.
.. In Dettagli tipo, immettere il nome utente e la password per gli host Oracle.
.. Selezionare il metodo di escalation dei privilegi corretto e immettere nome utente e password.






=== 2. Crea un progetto

. Vai su Risorse → Progetti e fai clic su Aggiungi.
+
.. Inserisci il nome e i dettagli dell'organizzazione.
.. Selezionare Git nel campo Tipo di credenziale di controllo del codice sorgente.
.. entrare `\https://github.com/NetApp-Automation/na_oracle19c_deploy.git` come URL di controllo della sorgente.
.. Fare clic su Salva.
.. Potrebbe essere necessario sincronizzare occasionalmente il progetto quando il codice sorgente cambia.






=== 3. Configurare Oracle host_vars

Le variabili definite in questa sezione vengono applicate a ciascun singolo server e database Oracle.

. Inserisci i parametri specifici del tuo ambiente nelle seguenti variabili host Oracle incorporate o nel modulo host_vars.



NOTE: Gli elementi in blu devono essere modificati per adattarli all'ambiente.



=== Configurazione VARS host

[source, shell]
----
######################################################################
##############      Host Variables Configuration        ##############
######################################################################

# Add your Oracle Host
ansible_host: "10.61.180.15"

# Oracle db log archive mode: true - ARCHIVELOG or false - NOARCHIVELOG
log_archive_mode: "true"

# Number of pluggable databases per container instance identified by sid. Pdb_name specifies the prefix for container database naming in this case cdb2_pdb1, cdb2_pdb2, cdb2_pdb3
oracle_sid: "cdb2"
pdb_num: "3"
pdb_name: "{{ oracle_sid }}_pdb"

# CDB listener port, use different listener port for additional CDB on same host
listener_port: "1523"

# CDB is created with SGA at 75% of memory_limit, MB. Consider how many databases to be hosted on the node and how much ram to be allocated to each DB. The grand total SGA should not exceed 75% available RAM on node.
memory_limit: "5464"

# Set "em_configuration: DBEXPRESS" to install enterprise manager express and choose a unique port from 5500 to 5599 for each sid on the host.
# Leave them black if em express is not installed.
em_configuration: "DBEXPRESS"
em_express_port: "5501"

# {{groups.oracle[0]}} represents first Oracle DB server as defined in Oracle hosts group [oracle]. For concurrent multiple Oracle DB servers deployment, [0] will be incremented for each additional DB server. For example,  {{groups.oracle[1]}}" represents DB server 2, "{{groups.oracle[2]}}" represents DB server 3 ... As a good practice and the default, minimum three volumes is allocated to a DB server with corresponding /u01, /u02, /u03 mount points, which store oracle binary, oracle data, and oracle recovery files respectively. Additional volumes can be added by click on "More NFS volumes" but the number of volumes allocated to a DB server must match with what is defined in global vars file by volumes_nfs parameter, which dictates how many volumes are to be created for each DB server.
host_datastores_nfs:
  - {vol_name: "{{groups.oracle[0]}}_u01", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
  - {vol_name: "{{groups.oracle[0]}}_u02", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
  - {vol_name: "{{groups.oracle[0]}}_u03", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
----
. Compila tutte le variabili nei campi blu.
. Dopo aver completato l'inserimento delle variabili, fare clic sul pulsante Copia nel modulo per copiare tutte le variabili da trasferire ad AWX o Tower.
. Torna ad AWX o Tower e vai su Risorse → Host, quindi seleziona e apri la pagina di configurazione del server Oracle.
. Nella scheda Dettagli, fare clic su Modifica e incollare le variabili copiate dal passaggio 1 nel campo Variabili nella scheda YAML.
. Fare clic su Salva.
. Ripetere questa procedura per tutti gli altri server Oracle presenti nel sistema.




=== 4. Configurare le variabili globali

Le variabili definite in questa sezione si applicano a tutti gli host Oracle, ai database e al cluster ONTAP .

. Inserisci i parametri specifici del tuo ambiente nelle seguenti variabili globali incorporate o nel modulo vars.



NOTE: Gli elementi in blu devono essere modificati per adattarli all'ambiente.

[source, shell]
----
#######################################################################
###### Oracle 19c deployment global user configuration variables ######
######  Consolidate all variables from ontap, linux and oracle   ######
#######################################################################

###########################################
### Ontap env specific config variables ###
###########################################

#Inventory group name
#Default inventory group name - 'ontap'
#Change only if you are changing the group name either in inventory/hosts file or in inventory groups in case of AWX/Tower
hosts_group: "ontap"

#CA_signed_certificates (ONLY CHANGE to 'true' IF YOU ARE USING CA SIGNED CERTIFICATES)
ca_signed_certs: "false"

#Names of the Nodes in the ONTAP Cluster
nodes:
 - "AFF-01"
 - "AFF-02"

#Storage VLANs
#Add additional rows for vlans as necessary
storage_vlans:
   - {vlan_id: "203", name: "infra_NFS", protocol: "NFS"}
More Storage VLANsEnter Storage VLANs details

#Details of the Data Aggregates that need to be created
#If Aggregate creation takes longer, subsequent tasks of creating volumes may fail.
#There should be enough disks already zeroed in the cluster, otherwise aggregate create will zero the disks and will take long time
data_aggregates:
  - {aggr_name: "aggr01_node01"}
  - {aggr_name: "aggr01_node02"}

#SVM name
svm_name: "ora_svm"

# SVM Management LIF Details
svm_mgmt_details:
  - {address: "172.21.91.100", netmask: "255.255.255.0", home_port: "e0M"}

# NFS storage parameters when data_protocol set to NFS. Volume named after Oracle hosts name identified by mount point as follow for oracle DB server 1. Each mount point dedicates to a particular Oracle files: u01 - Oracle binary, u02 - Oracle data, u03 - Oracle redo. Add additional volumes by click on "More NFS volumes" and also add the volumes list to corresponding host_vars as host_datastores_nfs variable. For multiple DB server deployment, additional volumes sets needs to be added for additional DB server. Input variable "{{groups.oracle[1]}}_u01", "{{groups.oracle[1]}}_u02", and "{{groups.oracle[1]}}_u03" as vol_name for second DB server. Place volumes for multiple DB servers alternatingly between controllers for balanced IO performance, e.g. DB server 1 on controller node1, DB server 2 on controller node2 etc. Make sure match lif address with controller node.

volumes_nfs:
  - {vol_name: "{{groups.oracle[0]}}_u01", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
  - {vol_name: "{{groups.oracle[0]}}_u02", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}
  - {vol_name: "{{groups.oracle[0]}}_u03", aggr_name: "aggr01_node01", lif: "172.21.94.200", size: "25"}

#NFS LIFs IP address and netmask

nfs_lifs_details:
  - address: "172.21.94.200" #for node-1
    netmask: "255.255.255.0"
  - address: "172.21.94.201" #for node-2
    netmask: "255.255.255.0"

#NFS client match

client_match: "172.21.94.0/24"

###########################################
### Linux env specific config variables ###
###########################################

#NFS Mount points for Oracle DB volumes

mount_points:
  - "/u01"
  - "/u02"
  - "/u03"

# Up to 75% of node memory size divided by 2mb. Consider how many databases to be hosted on the node and how much ram to be allocated to each DB.
# Leave it blank if hugepage is not configured on the host.

hugepages_nr: "1234"

# RedHat subscription username and password

redhat_sub_username: "xxx"
redhat_sub_password: "xxx"

####################################################
### DB env specific install and config variables ###
####################################################

db_domain: "your.domain.com"

# Set initial password for all required Oracle passwords. Change them after installation.

initial_pwd_all: "netapp123"
----
. Compilare tutte le variabili nei campi blu.
. Dopo aver completato l'inserimento delle variabili, fare clic sul pulsante Copia nel modulo per copiare tutte le variabili da trasferire ad AWX o Tower nel seguente modello di lavoro.




=== 5. Configurare e avviare il modello di lavoro.

. Crea il modello di lavoro.
+
.. Vai su Risorse → Modelli → Aggiungi e fai clic su Aggiungi modello di lavoro.
.. Inserisci il nome e la descrizione
.. Selezionare il tipo di lavoro; Esegui configura il sistema in base a un playbook, mentre Verifica esegue un'esecuzione di prova di un playbook senza effettivamente configurare il sistema.
.. Selezionare l'inventario, il progetto, il playbook e le credenziali corrispondenti per il playbook.
.. Selezionare all_playbook.yml come playbook predefinito da eseguire.
.. Incolla le variabili globali copiate dal passaggio 4 nel campo Variabili modello nella scheda YAML.
.. Selezionare la casella Richiedi all'avvio nel campo Tag lavoro.
.. Fare clic su Salva.


. Avvia il modello di lavoro.
+
.. Vai a Risorse → Modelli.
.. Fare clic sul modello desiderato e quindi su Avvia.
.. Quando all'avvio viene richiesto di immettere i tag di lavoro, digitare requirements_config.  Potrebbe essere necessario fare clic sulla riga Crea tag di lavoro sotto requirements_config per immettere il tag di lavoro.





NOTE: requirements_config garantisce che siano disponibili le librerie corrette per eseguire gli altri ruoli.

. Fare clic su Avanti e poi su Avvia per avviare il processo.
. Fare clic su Visualizza → Lavori per monitorare l'output e l'avanzamento del lavoro.
. Quando all'avvio viene richiesto di immettere i tag dei lavori, digitare ontap_config.  Potrebbe essere necessario fare clic sulla riga Crea "Tag lavoro" subito sotto ontap_config per immettere il tag lavoro.
. Fare clic su Avanti e poi su Avvia per avviare il processo.
. Fare clic su Visualizza → Lavori per monitorare l'output e l'avanzamento del lavoro
. Dopo aver completato il ruolo ontap_config, eseguire nuovamente il processo per linux_config.
. Vai a Risorse → Modelli.
. Selezionare il modello desiderato e quindi fare clic su Avvia.
. Quando all'avvio viene richiesto di digitare i tag del processo in linux_config, potrebbe essere necessario selezionare la riga Crea "tag processo" subito sotto linux_config per immettere il tag del processo.
. Fare clic su Avanti e poi su Avvia per avviare il processo.
. Selezionare Visualizza → Lavori per monitorare l'output e l'avanzamento del lavoro.
. Dopo aver completato il ruolo linux_config, eseguire nuovamente il processo per oracle_config.
. Vai a Risorse → Modelli.
. Selezionare il modello desiderato e quindi fare clic su Avvia.
. Quando all'avvio viene richiesto di immettere i tag dei processi, digitare oracle_config.  Potrebbe essere necessario selezionare la riga Crea "Tag lavoro" subito sotto oracle_config per immettere il tag lavoro.
. Fare clic su Avanti e poi su Avvia per avviare il processo.
. Selezionare Visualizza → Lavori per monitorare l'output e l'avanzamento del lavoro.




=== 6. Distribuisci un database aggiuntivo sullo stesso host Oracle

La parte Oracle del playbook crea un singolo database contenitore Oracle su un server Oracle per ogni esecuzione.  Per creare database contenitore aggiuntivi sullo stesso server, completare i seguenti passaggi.

. Rivedere le variabili host_vars.
+
.. Tornare al passaggio 2: configurare Oracle host_vars.
.. Modificare l'Oracle SID con una stringa di denominazione diversa.
.. Cambiare il numero della porta di ascolto.
.. Se si sta installando EM Express, modificare la porta EM Express con un numero diverso.
.. Copiare e incollare le variabili host riviste nel campo Variabili host Oracle nella scheda Dettagli configurazione host.


. Avviare il modello di processo di distribuzione solo con il tag oracle_config.
. Accedi al server Oracle come utente Oracle ed esegui i seguenti comandi:
+
[source, cli]
----
ps -ef | grep ora
----
+

NOTE: Questo elencherà i processi Oracle se l'installazione è stata completata come previsto e Oracle DB è stato avviato

. Accedi al database per controllare le impostazioni di configurazione del database e i PDB creati con i seguenti set di comandi.
+
[source, cli]
----
[oracle@localhost ~]$ sqlplus / as sysdba

SQL*Plus: Release 19.0.0.0.0 - Production on Thu May 6 12:52:51 2021
Version 19.8.0.0.0

Copyright (c) 1982, 2019, Oracle.  All rights reserved.

Connected to:
Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Version 19.8.0.0.0

SQL>

SQL> select name, log_mode from v$database;
NAME      LOG_MODE
--------- ------------
CDB2      ARCHIVELOG

SQL> show pdbs

    CON_ID CON_NAME                       OPEN MODE  RESTRICTED
---------- ------------------------------ ---------- ----------
         2 PDB$SEED                       READ ONLY  NO
         3 CDB2_PDB1                      READ WRITE NO
         4 CDB2_PDB2                      READ WRITE NO
         5 CDB2_PDB3                      READ WRITE NO

col svrname form a30
col dirname form a30
select svrname, dirname, nfsversion from v$dnfs_servers;

SQL> col svrname form a30
SQL> col dirname form a30
SQL> select svrname, dirname, nfsversion from v$dnfs_servers;

SVRNAME                        DIRNAME                        NFSVERSION
------------------------------ ------------------------------ ----------------
172.21.126.200                 /rhelora03_u02                 NFSv3.0
172.21.126.200                 /rhelora03_u03                 NFSv3.0
172.21.126.200                 /rhelora03_u01                 NFSv3.0
----
+
Ciò conferma che dNFS funziona correttamente.

. Connettersi al database tramite listener per verificare la configurazione del listener Oracle con il seguente comando.  Modificare la porta di ascolto e il nome del servizio di database appropriati.
+
[source, cli]
----
[oracle@localhost ~]$ sqlplus system@//localhost:1523/cdb2_pdb1.cie.netapp.com

SQL*Plus: Release 19.0.0.0.0 - Production on Thu May 6 13:19:57 2021
Version 19.8.0.0.0

Copyright (c) 1982, 2019, Oracle.  All rights reserved.

Enter password:
Last Successful login time: Wed May 05 2021 17:11:11 -04:00

Connected to:
Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Version 19.8.0.0.0

SQL> show user
USER is "SYSTEM"
SQL> show con_name
CON_NAME
CDB2_PDB1
----
+
Ciò conferma che l'ascoltatore Oracle funziona correttamente.





=== Dove rivolgersi per chiedere aiuto?

Se hai bisogno di aiuto con il toolkit, unisciti a noilink:https://netapppub.slack.com/archives/C021R4WC0LC["Canale Slack di supporto della community NetApp Solution Automation"] e cerca il canale solution-automation per pubblicare le tue domande o richieste.
